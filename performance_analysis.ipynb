{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749bea72",
   "metadata": {},
   "source": [
    "# 性能分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9206c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "import math \n",
    "import random\n",
    "from node2vec.edges import HadamardEmbedder\n",
    "import sklearn\n",
    "import os\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f3e76",
   "metadata": {},
   "source": [
    "## 定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94c701d",
   "metadata": {},
   "source": [
    "### 定义嵌入函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f2baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_functions = {\n",
    "    \"hadamard\": lambda a, b: a * b,\n",
    "    \"average\": lambda a, b: 0.5 * (a + b),\n",
    "    \"L1\": lambda a, b: np.abs(a - b),\n",
    "    \"L2\": lambda a, b: np.abs(a - b) ** 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474436dd",
   "metadata": {},
   "source": [
    "### 将嵌入向量文件转换为 Python 字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d88b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_to_dictionary(emb_file_name):\n",
    "    dictionary = {}\n",
    "\n",
    "    with open(emb_file_name, 'r') as f:\n",
    "\n",
    "        next(f)  # skip first line (file comment line)\n",
    "        for line in f:\n",
    "            elements = line.split(' ')\n",
    "            node_id = elements.pop(0)\n",
    "            embedding = []\n",
    "            for e in elements:\n",
    "                embedding.append(float(e))\n",
    "\n",
    "            dictionary[node_id] = embedding\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92590265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dc54b65",
   "metadata": {},
   "source": [
    "### 从正训练集中生成测试集，并生成用于训练和测试的负样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "146197dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_and_training_set(positive_training_set, percentage, negative_percentage, min_degree):\n",
    "    positive_test_set = nx.Graph()\n",
    "    # 将正训练集中的节点添加到原本为空测试图中\n",
    "    positive_test_set.add_nodes_from(positive_training_set)\n",
    "\n",
    "    # 生成用于训练的负样本：从正训练集中获取所有不存在的边（负样本）的列表all_negative_samples。然后，创建一个布尔数组acceptable，用于跟踪哪些负样本是可接受的\n",
    "    all_negative_samples = list(nx.non_edges(positive_training_set))\n",
    "    accetable = [True for i in range(len(all_negative_samples))]\n",
    "\n",
    "    node_number = positive_training_set.number_of_nodes()\n",
    "    node_list = positive_training_set.nodes()\n",
    "\n",
    "    # 将正训练集中的一部分边移动到测试集中\n",
    "    for node in node_list:\n",
    "\n",
    "        percent = int(round((percentage * len(positive_training_set.edges(node)))))\n",
    "        edges = list(positive_training_set.edges(node))\n",
    "        counter = 0\n",
    "        edge_count = len(edges)\n",
    "\n",
    "        for attempt in range(edge_count):\n",
    "\n",
    "            if len(edges) > 0:\n",
    "                u, v = edges.pop(random.randrange(len(edges)))\n",
    "\n",
    "                if counter < percent:\n",
    "                    if (positive_training_set.degree[u] > min_degree and positive_training_set.degree[v] > min_degree):\n",
    "                        positive_test_set.add_edge(u, v)\n",
    "                        positive_training_set.remove_edge(u, v)\n",
    "                        counter += 1\n",
    "\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # 生成用于训练的负样本\n",
    "    negative_edges_for_training = []\n",
    "\n",
    "    for i in range(int((2 * negative_percentage) * len(positive_training_set.edges()))):\n",
    "        index = random.randint(0, len(all_negative_samples))\n",
    "        negative_edges_for_training.append(all_negative_samples[index])\n",
    "        accetable[index] = False\n",
    "\n",
    "    negative_training_set = nx.Graph()\n",
    "    negative_training_set.add_nodes_from(positive_training_set)\n",
    "    negative_training_set.add_edges_from(negative_edges_for_training)\n",
    "    \n",
    "    # 从 all_negative_samples 中随机选择一定数量的负样本，并将它们添加到负测试集\n",
    "    negative_edges_for_test = []\n",
    "\n",
    "    i = 0\n",
    "    # 循环直到：生成的负样本数量超过预设的负样本比例*正训练集中边的数量的两倍\n",
    "    while i < (int((2 * negative_percentage) * len(positive_training_set.edges()))):\n",
    "\n",
    "        index = random.randint(0, len(all_negative_samples))\n",
    "\n",
    "        # 如果为True（表示未被选择过），则将该负样本添加到负测试集中，并设置为 False\n",
    "        if accetable[index]:\n",
    "            negative_edges_for_test.append(all_negative_samples[index])\n",
    "            accetable[index] = False\n",
    "            i += 1\n",
    "\n",
    "    negative_test_set = nx.Graph()\n",
    "    negative_test_set.add_nodes_from(positive_training_set)\n",
    "    negative_test_set.add_edges_from(negative_edges_for_test)\n",
    "\n",
    "    return positive_test_set, positive_training_set, negative_test_set, negative_training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f2fcf",
   "metadata": {},
   "source": [
    "###  为每条边生成标签，正样本为1，负样本为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9711c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_and_labels(positive, negative):\n",
    "    edges = list(positive) + list(negative)\n",
    "    labels = np.zeros(len(edges))\n",
    "    labels[:len(positive)] = 1\n",
    "    return edges, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229cd20c",
   "metadata": {},
   "source": [
    "### 从正样本和负样本中获取边和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d8537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_to_features(model, edge_list, edge_function, dimensions): # d=128????   32!!!!!\n",
    "    \n",
    "    n_tot = len(edge_list)\n",
    "    features_vec = np.empty((n_tot, dimensions), dtype='f')\n",
    "    # print(model.wv.key_to_index)\n",
    "    global mode\n",
    "    for ii in range(n_tot):\n",
    "        v1, v2 = edge_list[ii]\n",
    "        \n",
    "        \n",
    "        if mode != \"deepwalk\":\n",
    "            \n",
    "            emb1 = np.asarray(model.wv[str(v1)])  # wyt\n",
    "            emb2 = np.asarray(model.wv[str(v2)])  # wyt\n",
    "        \n",
    "        \n",
    "#         emb1 = np.asarray(model.wv.get_vector(str(v1)))  # wyt\n",
    "#         emb2 = np.asarray(model.wv.get_vector(str(v2)))  # wyt\n",
    "\n",
    "        else:\n",
    "            emb1 = np.asarray(model.wv[v1])  # wyt\n",
    "            emb2 = np.asarray(model.wv[v2])  # wyt\n",
    "#         print(\"****\")\n",
    "#         print(n_tot)\n",
    "#         print(emb1)\n",
    "#         print(emb2)\n",
    "        features_vec[ii] = edge_function(emb1, emb2)  # Calculate edge feature\n",
    "\n",
    "    return features_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cddd89c",
   "metadata": {},
   "source": [
    "### 训练/测试/评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f948f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_and_testing(filename, mode):\n",
    "    # 读取图数据并创建训练集和测试集\n",
    "    graph = nx.Graph()\n",
    "    G = nx.read_edgelist(filename, create_using=graph, nodetype=int, data=(('weight', int),))\n",
    "    print('OK - Graph created')  # debug\n",
    "\n",
    "    min_degree = 2\n",
    "\n",
    "    print('Creating training and test set...')  # debug\n",
    "    positive_test_set, positive_training_set, negative_test_set, negative_training_set = create_test_and_training_set(G,\n",
    "                                                                                                                      0.2,\n",
    "                                                                                                                      0.5,\n",
    "                                                                                                                      min_degree)\n",
    "    edges, training_labels = get_edges_and_labels(positive_training_set.edges(), negative_training_set.edges())\n",
    "    print('OK - Training and test set created')  # debug\n",
    "\n",
    "    \n",
    "    # 参数设定\n",
    "    dims = 32\n",
    "    gamma = 10 # 每个节点作为起始点生成随机游走序列个数\n",
    "    walk_length = 5 # 随机游走序列最大长度\n",
    "\n",
    "    # 使用node2vec或deepwalk模型进行节点嵌入和边嵌入\n",
    "    if mode == \"deepwalk\":\n",
    "        \n",
    "        def get_randomwalk(node, path_length):\n",
    "            '''\n",
    "            输入起始节点和路径长度，生成随机游走节点序列\n",
    "            '''\n",
    "\n",
    "            random_walk = [node]\n",
    "\n",
    "            for i in range(path_length-1):\n",
    "                # 汇总邻接节点\n",
    "                temp = list(G.neighbors(node))\n",
    "                temp = list(set(temp) - set(random_walk))    \n",
    "                if len(temp) == 0:\n",
    "                    break\n",
    "                # 从邻接节点中随机选择下一个节点\n",
    "                random_node = random.choice(temp)\n",
    "                random_walk.append(random_node)\n",
    "                node = random_node\n",
    "\n",
    "            return random_walk\n",
    "                \n",
    "        \n",
    "        \n",
    "        all_nodes = list(G.nodes())\n",
    "        \n",
    "        random_walks = []\n",
    "        from tqdm import tqdm\n",
    "        for n in tqdm(all_nodes): # 遍历每个节点\n",
    "            for i in range(gamma): # 每个节点作为起始点生成gamma个随机游走序列\n",
    "                random_walks.append(get_randomwalk(n, walk_length))\n",
    "        \n",
    "        from gensim.models import Word2Vec\n",
    "        model = Word2Vec(vector_size=32, # Embedding维数\n",
    "                 window=1, # 窗口宽度\n",
    "                 sg=1, # Skip-Gram\n",
    "                 hs=0, # 不加分层softmax\n",
    "                 negative=10, # 负采样\n",
    "                 alpha=0.03,  # 初始学习率\n",
    "                 min_alpha=0.0007, # 最小学习率\n",
    "                 seed=14 # 随机数种子\n",
    "                )\n",
    "        # 用随机游走序列构建词汇表\n",
    "        model.build_vocab(random_walks, progress_per=2)\n",
    "        model.train(random_walks, total_examples=model.corpus_count, epochs=50, report_delay=1)\n",
    "\n",
    "    else:  # Node2Vec mode\n",
    "        print('Node2Vec...')  # debug\n",
    "        node2vec = Node2Vec(positive_training_set, dimensions=dims, walk_length=walk_length, num_walks=gamma, workers=4)\n",
    "        model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "    print('OK - Model created')  # debug\n",
    "\n",
    "    # 边嵌入\n",
    "    print('Edge embedding...')  # debug\n",
    "    X_Hadamard = edges_to_features(model, edges, edge_functions['hadamard'], dims)\n",
    "    X_L1 = edges_to_features(model, edges, edge_functions['L1'], dims)\n",
    "    X_L2 = edges_to_features(model, edges, edge_functions['L2'], dims)\n",
    "    print('OK - Embedding done')  # debug\n",
    "\n",
    "    # LOGISTIC REGRESSION\n",
    "\n",
    "    print('Logistic regression - Computing scores...')  # debug\n",
    "\n",
    "    # 采用逻辑回归模型训练\n",
    "    clf_Hadamard = LogisticRegression()\n",
    "    clf_L1 = LogisticRegression()\n",
    "    clf_L2 = LogisticRegression()\n",
    "\n",
    "    clf_Hadamard.fit(X_Hadamard, training_labels)\n",
    "    clf_L1.fit(X_L1, training_labels)\n",
    "    clf_L2.fit(X_L2, training_labels)\n",
    "\n",
    "    # TESTING - Prediction\n",
    "\n",
    "    # 将正测试集的边转换为列表形式存储在test_edges中\n",
    "    test_edges = list(positive_test_set.edges())\n",
    "\n",
    "    positive_emb_test_Hadamard = edges_to_features(model, test_edges, edge_functions['hadamard'], dims)\n",
    "    positive_emb_test_L1 = edges_to_features(model, test_edges, edge_functions['L1'], dims)\n",
    "    positive_emb_test_L2 = edges_to_features(model, test_edges, edge_functions['L2'], dims)\n",
    "\n",
    "    # Embedding -- Negative test set\n",
    "    test_edges = list(negative_test_set.edges())\n",
    "\n",
    "    negative_emb_test_Hadamard = edges_to_features(model, test_edges, edge_functions['hadamard'], dims)\n",
    "    negative_emb_test_L1 = edges_to_features(model, test_edges, edge_functions['L1'], dims)\n",
    "    negative_emb_test_L2 = edges_to_features(model, test_edges, edge_functions['L2'], dims)\n",
    "\n",
    "    # Prepare whole test set for every embedding function\n",
    "    Hadamard_edges, y_test_Hadamard = get_edges_and_labels(positive_emb_test_Hadamard, negative_emb_test_Hadamard)\n",
    "    L1_edges, y_test_L1 = get_edges_and_labels(positive_emb_test_L1, negative_emb_test_L1)\n",
    "    L2_edges, y_test_L2 = get_edges_and_labels(positive_emb_test_L2, negative_emb_test_L2)\n",
    "\n",
    "    # 使用训练好的逻辑回归分类器分别对嵌入函数得到的特征向量进行预测\n",
    "    print('Testing...')  # debug\n",
    "    y_pred_test_Hadamard = clf_Hadamard.predict(Hadamard_edges)\n",
    "    y_pred_test_L1 = clf_L1.predict(L1_edges)\n",
    "    y_pred_test_L2 = clf_L2.predict(L2_edges)\n",
    "\n",
    "    # 计算准确率评分\n",
    "    score_Hadamard = sklearn.metrics.accuracy_score(y_test_Hadamard, y_pred_test_Hadamard)\n",
    "    score_L1 = sklearn.metrics.accuracy_score(y_test_L1, y_pred_test_L1)\n",
    "    score_L2 = sklearn.metrics.accuracy_score(y_test_L2, y_pred_test_L2)\n",
    "\n",
    "    return score_Hadamard, score_L1, score_L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440bdce7",
   "metadata": {},
   "source": [
    "## 开始性能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ca7e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "filename = '/data/bilibili_tag1(d).txt'  # -------------------------------\n",
    "if not (os.path.isfile(filename)):\n",
    "    print('Error: Dataset does not exist')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3470c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 命令参数r即runs，实验进行的次数（最终评分取平均值）\n",
    "runs = 10\n",
    "mode = 'Node2Vec'\n",
    "Hadamard_sum = L1_sum = L2_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e699a311",
   "metadata": {},
   "source": [
    "### 使用Node2Vec对数据集进行训练和测试，并生成评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42356ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      " \n",
      "Starting iteration 1\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n",
      "Node2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b8e5cbd735467fa71363d0010b53a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 1 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 2\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n",
      "Node2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83363a3a0d0843f89e93250c5d9f685a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 2 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 3\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n",
      "Node2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61385cd8edd4154bf553fd5b1299f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 3 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 4\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n",
      "Node2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d440081211445e6a61745a6f34af9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 4 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 5\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n",
      "Node2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb7063a4f094d949432d4cd3d1c8a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 5 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 6\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n",
      "Node2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b2fd051ce2491dba318398a346be5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 6 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 7\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n",
      "Node2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151ed157b1724c19879ad54ac4fc0380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 7 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 8\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n",
      "Node2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3945964a2d154dca8cd7aa3d0d2e5edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 8 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 9\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n",
      "Node2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4602d1eed6a64963bdd9a2381296bc15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 9 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 10\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n",
      "Node2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8430235e308a4e9eba260afea71561e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 10 finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(runs):\n",
    "    print('##############################\\n ')\n",
    "    print('Starting iteration ' + str(i + 1))  # Logging\n",
    "    score_Hadamard, score_L1, score_L2 = training_and_testing(filename, mode)\n",
    "    Hadamard_sum += score_Hadamard\n",
    "    L1_sum += score_L1\n",
    "    L2_sum += score_L2\n",
    "    print('Iteration ' + str(i + 1) + ' finished\\n')  # Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17fdce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hadamard_avg_score = Hadamard_sum / (float(runs))\n",
    "L1_avg_score = L1_sum / (float(runs))\n",
    "L2_avg_score = L2_sum / (float(runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08170c",
   "metadata": {},
   "source": [
    "### 输出评分结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f690dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec -> accuracy for 10 executions on bili.txt dataset:\n",
      "Hadamard:0.8559953434225844\n",
      "L1: 0.5749708963911525\n",
      "L2: 0.5062863795110595\n"
     ]
    }
   ],
   "source": [
    "print(\"Node2Vec -> accuracy for \" + str(runs) + \" executions on \" + filename + \" dataset:\")\n",
    "print(\"Hadamard:\" + str(Hadamard_avg_score) + \"\\n\\r\" + \"L1: \" + str(L1_avg_score) + \"\\n\\r\" + \"L2: \" + str(L2_avg_score) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03598afb",
   "metadata": {},
   "source": [
    "### 使用deepwalk进行相同的实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efc354a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      " \n",
      "Starting iteration 1\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 559/559 [00:00<00:00, 13982.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 1 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 2\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 559/559 [00:00<00:00, 13982.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 2 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 3\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 559/559 [00:00<00:00, 13982.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 3 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 4\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 559/559 [00:00<00:00, 18643.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 4 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 5\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 559/559 [00:00<00:00, 18643.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 5 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 6\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 559/559 [00:00<00:00, 13982.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 6 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 7\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 559/559 [00:00<00:00, 18643.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 7 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 8\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 559/559 [00:00<00:00, 13982.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 8 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 9\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 559/559 [00:00<00:00, 13982.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 9 finished\n",
      "\n",
      "##############################\n",
      " \n",
      "Starting iteration 10\n",
      "OK - Graph created\n",
      "Creating training and test set...\n",
      "OK - Training and test set created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 559/559 [00:00<00:00, 13982.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Model created\n",
      "Edge embedding...\n",
      "OK - Embedding done\n",
      "Logistic regression - Computing scores...\n",
      "Testing...\n",
      "Iteration 10 finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mode = \"deepwalk\"\n",
    "Hadamard_sum = L1_sum = L2_sum = 0\n",
    "for i in range(runs):\n",
    "    print('##############################\\n ')\n",
    "    print('Starting iteration ' + str(i + 1))  # Logging\n",
    "    score_Hadamard, score_L1, score_L2 = training_and_testing(filename, mode)\n",
    "    Hadamard_sum += score_Hadamard\n",
    "    L1_sum += score_L1\n",
    "    L2_sum += score_L2\n",
    "    print('Iteration ' + str(i + 1) + ' finished\\n')  # Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b75905f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hadamard_avg_score_d = Hadamard_sum / (float(runs))\n",
    "L1_avg_score_d = L1_sum / (float(runs))\n",
    "L2_avg_score_d = L2_sum / (float(runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd2894af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepWalk -> accuracy for 10 executions on bili.txt dataset:\n",
      "Hadamard:0.7926658905704307\n",
      "L1: 0.6682188591385332\n",
      "L2: 0.6639115250291037\n"
     ]
    }
   ],
   "source": [
    "print(\"DeepWalk -> accuracy for \" + str(runs) + \" executions on \" + filename + \" dataset:\")\n",
    "print(\"Hadamard:\" + str(Hadamard_avg_score_d) + \"\\n\\r\" + \"L1: \" + str(L1_avg_score_d) + \"\\n\\r\" + \"L2: \" + str(L2_avg_score_d) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b295c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
